---
title: "Google I/O 2024の新たなイノベーション：生成AIとその応用例"
categories:
  - 技術
tags:
  - 生成AI
  - クラウドコンピューティング
---
Google I/O 2024では、Google Researchの先進的な技術が多数紹介されました。ここでは、その中でも特に注目すべきプロジェクトと生成AIの最新進展について解説します。

## Ask Photos: 写真の新しい検索体験

先週のGoogle I/O 2024で発表されたAsk Photosは、Googleフォトの新機能で、Geminiモデルを利用してユーザーの質問に応じた写真検索を可能にします。従来のキーワード検索に依存するのではなく、ユーザーが具体的なメモリーや写真内の特定の情報を質問することで、該当する写真を見つけ出します。この機能は、自然言語処理(NLP)[^4]とベクトルベースの検索[^7]を組み合わせ、従来のメタデータ検索を拡張します。

## StyleDrop: 無限のワンダーランド

StyleDropは、ユーザーが提供する参照画像を基に特定の視覚スタイルで画像を生成する技術です。この生成画像技術には、画像生成モデル[^11]が使われており、スタイル化されたテキストから画像を生成する際の精度が向上します。プロジェクト「Infinite Wonderland」では、ルイス・キャロルの『不思議の国のアリス』を現代の4人のアーティストの手で再解釈し、異なるスタイルで新しいイラストを生成しました。

## LearnLM: 学習体験のパーソナライズ

LearnLMは、Geminiを基に学習用に調整された新しいモデル群です。このモデルは、クイズ形式の評価機能を持つQuizMeを通じて、ユーザーが学習過程を進めるのを支援します。QuizMeは、大規模言語モデル(LLM)[^9]の能力を駆使し、質問生成、ヒント提供、回答評価、要約などを行います。

## Med-Gemini: 医療分野への応用

Med-Geminiは、医療分野に特化した生成AIモデルです。最新のMedQAベンチマークでは91.1%の正確性を達成し、さらに3D脳CTスキャンの解釈やポリジーニックリスクスコア[^14]を用いた健康予測にも対応しています。

## Illuminate: 学術論文の音声対話型解説

Illuminateは、学術論文の主要ポイントを音声化し、対話形式で提供する実験的なプロダクトです。このシステムは、Geminiの長文コンテキスト処理能力とマルチモーダル機能[^8]を活用して、複雑な内容を理解しやすい形で提供します。音声生成にはAudioLM[^15]が使用され、生成された内容にはSynthID[^13]でのウォーターマークが埋め込まれています。

## Google Quantum AI: 量子コンピューティングの未来

Googleは、量子コンピューティングの分野でも重要な取り組みを進めています。Google I/Oでは「量子コンピューティングの未来」という講演で、量子コンピューティング[^12]の基本から将来の応用例について説明が行われました。電気自動車向けの新しいバッテリー開発や、実用的な核融合エネルギーの解決策などが紹介されました。

## Veo: 高解像度ビデオ生成モデル

Veoは、Google DeepMindから発表された新しいビデオ生成モデルです。このモデルは、自然言語と画像の生成の進展を基にしており、高解像度のビデオを作成できる能力を持っています。Veoは他のモデルと連携して、高品質な動画生成を実現します。

## まとめ

Google I/O 2024で紹介された革新的な技術は、生成AIの新たな可能性を示しています。これらの技術は、ユーザーの体験を向上させるだけでなく、医療や教育などの幅広い分野で革新をもたらす可能性を秘めています。

## 参照URL
[^1]: [Machine Intelligence](https://ejje.weblio.jp/content/machine+intelligence)
[^2]: [Machine Perception](https://en.wikipedia.org/wiki/Machine_perception)
[^3]: [Machine Translation](https://phrase.com/ja/blog/posts/machine-translation/)
[^4]: [Natural Language Processing](https://www.keyence.co.jp/ss/general/iot-glossary/natural-language-processing.jsp#:~:text=%E3%80%8C%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%EF%BC%88NLP%EF%BC%9A,%E3%81%AE%E6%8A%80%E8%A1%93%E3%81%AE%E3%81%93%E3%81%A8%E3%81%A7%E3%81%99%E3%80%82)
[^5]: [Speech Processing](https://ejje.weblio.jp/content/speech+processing)
[^6]: [Algorithms & Optimization](https://eow.alc.co.jp/search?q=algorithm)
[^7]: [Vector-based retrieval](https://medium.com/@PolonioliAI/vector-based-retrieval-3ec1b3df6489)
[^8]: [Multimodal capabilities](https://docs.yellow.ai/docs/glossary/multimodal-capabilities)
[^9]: [Large language models (LLMs)](https://atmarkit.itmedia.co.jp/ait/articles/2303/13/news013.html)
[^10]: [Text-to-image generation](https://staffing.archetyp.jp/magazine/text-to-image/)
[^11]: [Text prompt engineering](https://atmarkit.itmedia.co.jp/ait/articles/2309/20/news014.html)
[^12]: [Quantum computing](https://aws.amazon.com/jp/what-is/quantum-computing/#:~:text=%E9%87%8F%E5%AD%90%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%AF%E3%80%81%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF,%E9%96%8B%E7%99%BA%E3%81%8C%E5%90%AB%E3%81%BE%E3%82%8C%E3%81%BE%E3%81%99%E3%80%82)
[^13]: [Polygenic risk scores](https://jp.illumina.com/areas-of-interest/complex-disease-genomics/polygenic-risk-scores.html#:~:text=%E3%83%9D%E3%83%AA%E3%82%B8%E3%83%8B%E3%83%83%E3%82%AF%E3%83%AA%E3%82%B9%E3%82%AF%E3%82%B9%E3%82%B3%E3%82%A2%EF%BC%88%E5%A4%9A,%E3%82%92%E4%BA%88%E6%B8%AC%E3%81%99%E3%82%8B%E6%89%8B%E6%B3%95%E3%81%A7%E3%81%99%E3%80%82)
[^14]: [SynthID](https://deepmind.google/technologies/synthid/)
[^15]: [AudioLM](https://arxiv.org/abs/2209.03143)
[^16]: [Generative AI agents](https://www.oracle.com/jp/artificial-intelligence/generative-ai/agents/)
@@@