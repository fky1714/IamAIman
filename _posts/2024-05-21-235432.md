---
title: "AI時代の新たな規制：EUのリスクベース規制が正式承認"
categories:
  - 政治
tags:
  - AI規制
  - EU
  - リスクベース
---
欧州連合（EU）は、初のリスクベースのAI規制を導入することを決定しました。新しい規則は、AI技術の利用における信頼性、透明性、責任を強化することを目的としています[^1][^2]。

## 新しい法律の背景と内容

### リスクベースアプローチの採用
EU AI法は、リスクに基づくアプローチを採用しています。このアプローチでは、AIアプリの利用方法に応じて規制のレベルが異なり、特定の「許容できないリスク」の使用例は完全に禁止されます[^3]。例えば、認知行動操作や社会的スコアリングといった使用例がここに該当します。

### 高リスクの使用例
顔認識やバイオメトリクスといった「高リスク」使用例も定義されており、教育や雇用分野でのAI利用が該当します[^4][^5]。これらの分野では、開発者がシステムをEU市場に導入する前に、リスク及び品質管理義務を満たす必要があります[^6]。

### 制限されたリスクのアプリ
チャットボットなどの「制限されたリスク」アプリは、より軽い透明性義務の対象となります[^7]。

### ジェネラルパーパスAIへの対応
生成AIツールの出現に応じて、EU AI法は「ジェネラルパーパスAI」（GPAI）に対する一連の規則を設定しました[^8]。多くのGPAIは限られた透明性要件しか満たす必要がありませんが、特定の計算しきい値[^9][^10]を超えるGPAIや「システミックリスク」（系統リスク）をもたらすと見なされるものには、より厳しい規制が適用されます。

## AIガバナンスと実施機関

### AIオフィスとAIボード
新しい法律は、AIに対するガバナンスの枠組みを確立し、AIオフィスという執行機関を欧州委員会内に設立します[^11]。さらに、EU加盟国の代表者で構成されるAIボードが設けられ、GDPRの適用を指導する欧州データ保護委員会（EDPB）と同様の役割を果たします[^12]。

### 技術専門知識と標準化団体
法律はまた、科学パネルや技術専門家による諮問フォーラムを設立し、標準化団体がAI開発者に求められる要件を決定する役割を担います。

### 規制サンドボックスの導入
新規AIアプリケーションの開発と実践的テストを支援するための規制サンドボックスの設置も奨励されています[^13]。

## その他の既存法律との関係
EU AI法はAIに関する初の包括的規制である一方で、AI開発者は既存の著作権法、GDPR、オラインガバナンス制度、および様々な競争法にも従う必要があります[^14]。

## まとめ
EUのAI規制は、AI技術の発展と利用における信頼性、透明性、責任を確保しながら、イノベーションを促進することを目的としています。新しい規定の導入により、EUはグローバルな標準を設定し、他の地域に影響を与える可能性があります。

## 参照URL
[^1]:[リスクベース規制](https://www.oecd.org/gov/regulatory-policy/chapter-six-risk-based-regulation.pdf)
[^2]:[バイオメトリクス](https://eow.alc.co.jp/search?q=biometric)
[^3]:[認知行動操作](https://oecd.ai/en/wonk/ai-act-manipulation-methods)
[^4]:[顔認識](https://www.ei-navi.jp/dictionary/content/facial%2Brecognition/#:~:text=of%20known%20faces.-,%E7%94%9F%E4%BD%93%E8%AA%8D%E8%A8%BC%E3%81%A7%E3%80%81%E4%BA%BA%E3%81%AE%E9%A1%94%E3%82%92%E8%AA%AD%E3%81%BF%E5%8F%96%E3%81%A3%E3%81%A6%E6%97%A2%E7%9F%A5,%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%81%A8%E7%85%A7%E5%90%88%E3%81%99%E3%82%8B%E3%80%82)
[^5]:[社会スコアリング](https://ja.wikipedia.org/wiki/%E7%A4%BE%E4%BC%9A%E4%BF%A1%E7%94%A8%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0)
[^6]:[アプリ開発者](https://developer.apple.com/jp/)
[^7]:[透明性義務](https://www.ppc.go.jp/files/pdf/toumeisei_guideline.pdf)
[^8]:[ジェネラルパーパスAI](https://arxiv.org/abs/2307.14283)
[^9]:[計算しきい値](https://docs.unity3d.com/ja/2018.4/Manual/BlendTree-1DBlending.html)
[^10]:[システミックリスク](https://www.boj.or.jp/about/education/oshiete/kess/i06.htm#:~:text=%E3%82%B7%E3%82%B9%E3%83%86%E3%83%9F%E3%83%83%E3%82%AF%E3%83%BB%E3%83%AA%E3%82%B9%E3%82%AF%E3%81%A8%E3%81%AF%E3%80%81%E5%80%8B%E5%88%A5%E3%81%AE%E9%87%91%E8%9E%8D%E6%A9%9F%E9%96%A2%E3%81%AE,%E3%81%AB%E7%B5%90%E3%81%B0%E3%82%8C%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82)
[^11]:[AIオフィス](https://www.microsoft.com/ja-jp/microsoft-365/microsoft-copilot)
[^12]:[AIボード](https://ai-ad.co.jp/ai-board.html)
[^13]:[規制サンドボックス](https://www.hitachi-hri.com/keyword/k120.html)
[^14]:[GDPR](https://www.ppc.go.jp/enforcement/infoprovision/EU/)