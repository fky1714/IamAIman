---
title: "LLMの適応と地ならし：AGREEフレームワークの進化"
categories:
  - テクノロジー
tags:
  - 生成AI
  - モデル適応
---
大規模言語モデル（LLM）がより信頼性の高い引用生成のために適応する方法について解説します。

## AGREEフレームワークの紹介

### 背景
近年、大規模言語モデル（LLM）は、多段式推論、計画生成、APIやツールの使用といった多様な能力で驚くべき進展を示しています。しかし、現実世界での信頼性には課題があり、「幻覚」と呼ばれる現象が発生します。これは、モデルがあり得るが事実とは異なる情報を生成する状況で、特にニュース報道や教育コンテンツといった正確性が求められる領域でリスクを増します。

### 幻覚問題への対策
「地ならし」は、LLMの主張を信頼できる情報源に基づかせる方法で、この問題に対処します。これにより、一貫性と有用性のある回答を提供し、その主張を外部知識の引用で裏付けることができます。

## AGREEフレームワークとは

### 目的と方法
私たちは、LLMの信頼性を高めるためにAGREE（Adaptation for GRounding EnhancEment）という新しいフレームワークを紹介します。AGREEは、LLMが自分の主張を自己地ならしし、正確な引用を提供することで、ユーザーの信頼を向上させ、幅広い応用可能性を広げます。これによる改良は、従来のプロンプティングベースやポストホックな引用アプローチに比べて30%以上の相対的な改善を達成しています。

### 従来のアプローチとの違い
従来の地ならしの改善研究には二つの主要なパラダイムがあります。一つは追加の自然言語推論（NLI）モデルを使用して後から引用を追加する方法ですが、これはLLMの埋め込み内の知識に大きく依存し、それ以外の事実には適用が難しいです。もう一つは、プロンプトによる少数のデモンストレーションからの学習に基づく方法ですが、これも実際には最適な地ならしの質を提供しません。

### AGREEのプロセス
AGREEは、学習に基づく適応とテスト時の適応（TTA）を組み合わせた包括的なアプローチを採用しています。前訓練されたLLMの上にチューニングを行うことで、自己地ならしと正確な引用を提供する能力を持たせます。チューニングには、高品質な地ならしされた回答（引用付き）のデータを自動生成する方法を導入します。

### トレーニングプロセス
AGREEは、ラベル付けされていないクエリから合成データを収集し、基本LLMを適応LLMへとチューニングし、主張を自己地ならしできるようにします。具体的には、信頼できる情報源からパッセージを取り出し、基本LLMに提示して初期回答を生成します。次に、NLIモデル（ここではGoogleのTrueNLIモデルの変種）を使用し、主張がどのパッセージに支えられているかを判断し引用を追加します。最も地ならしされた回答を選択し、基本LLMをチューニングして引用を含むように教えます。

### テスト時適応（TTA）
テスト時には、AGREEはLLMが自己生成した引用を基に追加情報を積極的に取得するための反復推論戦略を導入します。このプロセスにより、LLMは自己地ならしの指針に従い、より良い回答を構築できます。

## 実験と評価

### 調査方法
AGREEの有効性を実証するために、五つのデータセット（NQ、StrategyQA、ASQA、QAMPARI、Enterprise）で広範囲な実験を行いました。比較対象としては従来のプロンプティングベースのベースライン（ICLCite）とポストホックな引用ベースライン（PostCite）を使用しました。

### 結果と重要なポイント
AGREEは、全データセットで競争力のあるベースラインを大幅に上回る結果を示しました。特に、LLMの地ならしと引用精度の両方で大幅な改善を達成しています。さらに、テスト時適応の有無に関わらず、AGREEは適応LLMの性能を一貫して向上させました。

## 結論
まとめると、AGREEは生成系AIの信頼性と検証可能性を向上させるための有効な学習ベースのアプローチを提供します。この包括的な適応能力により、実際の応答も改善されます。五つのデータセットでの評価により、AGREEの全体的な優位性が確認されました。

## 参考URL
- [Adaptation](https://ejje.weblio.jp/content/adaptation)
- [Grounding](https://eow.alc.co.jp/search?q=grounding)
- [Citation](https://www.ei-navi.jp/dictionary/content/citation/#:~:text=%E5%BC%95%E7%94%A8%EF%BC%8C%E5%BC%95%E7%94%A8%E6%96%87%EF%BC%8C%E5%BC%95%E7%94%A8%E5%8F%A5)
- [Hallucination](https://eow.alc.co.jp/search?q=hallucination)
- [Retrieval](https://eow.alc.co.jp/search?q=retrieval)
- [Test-time Adaptation](https://xpaperchallenge.org/cv/survey/cvpr2022_summaries/347/)
- [Model Fine-tuning](https://qiita.com/ksonoda/items/b9fd3e709aeae79629ff)
- [Prompting](https://eow.alc.co.jp/search?q=prompting)
- [Self-grounding](https://philarchive.org/archive/KOVWIW)
- [Citation Precision](http://evene.lefigaro.fr/citations/mot.php?mot=precision)
- [Citation Recall](https://www.ffcr.or.jp/fda21cfr/zaidan/CFR21.nsf/876757280c46e65e4925659f000b0cc0/915618a8b053180f492565e600227c7102ec.html?OpenDocument)
- [External Knowledge](https://www.archbee.com/blog/internal-vs-external-knowledge-base)
- [Inference](https://ejje.weblio.jp/content/inference)
- [Supported Statements](https://docs.oracle.com/en/database/oracle/oracle-database/21/gmswn/supported-sql-statements.html)
- [Response Accuracy](https://www.linguee.jp/%E8%8B%B1%E8%AA%9E-%E6%97%A5%E6%9C%AC%E8%AA%9E/%E7%BF%BB%E8%A8%B3/response+accuracy.html)
