---
title: "AmpereとQualcommが手を組み、ArmベースのAIサーバを発表"
categories:
  - テクノロジー
tags:
  - AI
  - サーバ
---

AmpereとQualcommが手を組み、効率的なAI推論（インフェレンス）のための新しいArmベース[^1]のサーバを発表しました。このサーバは、AmpereのCPUとQualcommのCloud AI 100 Ultra AI推論チップを組み合わせたもので、特に大規模なAIモデルの処理能力に秀でています。

## AmpereとQualcommの提携の背景
AmpereとQualcommは、これまでそれぞれ独自にデータセンター向けのArmベースのチップを提供してきましたが、今回の提携により、AI向けの特化したサーバソリューションを実現しました。AmpereのCTOであるJeff Wittich氏は、AIのワークロードには一様な解決策は存在しないと述べており、Qualcommとの協力が重要であったと語っています。

## AmpereOneチップの特徴
新しい256コアのAmpereOneチップは、3nmプロセス[^3]で製造され、高効率なパフォーマンスと省電力性を兼ね備えています。また、このチップには12チャンネルのDDR5 RAM[^4]が搭載されており、より効果的なメモリアクセスが可能です。この新しいチップは、現在のところ一般提供前の段階にありますが、今年後半には市場に投入される予定です。

## 高いパフォーマンスと省電力性
Ampereの新しいサーバは、特にAI推論において高いパフォーマンスを発揮します。同社はNvidiaのA10 GPU[^5]と比較して、その効率性を強調しています。低電力で高い性能を発揮することにより、データセンターの運用コスト削減にも寄与します。

## NETINTとの新たなパートナーシップ
さらに、AmpereはNETINTとも提携し、ビデオ処理に特化したソリューションを提供します。この新しいサーバは、360のライブビデオチャンネルを並行してトランスコード[^6]し、OpenAIのWhisperモデル[^7]を用いた音声からテキストへの変換で40のストリームに字幕を付けることができます。

## まとめ
AmpereとQualcommの提携は、生成AIによる推論の分野に新しい可能性をもたらします。高効率でパワフルなサーバにより、大規模なAIモデルの処理が容易になり、コストも削減されるでしょう。

## 参照URL
[^1]: [What is ARM processor](https://www.redhat.com/ja/topics/linux/what-is-arm-processor)
[^3]: [3 nm process](https://en.wikipedia.org/wiki/3_nm_process)
[^4]: [DDR5 RAM](https://kakaku.com/pc/pc-memory/itemlist.aspx?pdf_Spec101=7)
[^5]: [Nvidia A10 GPUs](https://www.nvidia.com/ja-jp/data-center/products/a10-gpu/)
[^6]: [Transcoding](https://www.cdnetworks.com/ja/media-delivery-blog/what-is-transcoding/#:~:text=%E7%B0%A1%E5%8D%98%E3%81%AB%E8%A8%80%E3%81%88%E3%81%B0%E3%80%81%E3%83%88%E3%83%A9%E3%83%B3%E3%82%B9,%E3%83%93%E3%83%87%E3%82%AA%20%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E3%81%AE%E3%82%B9%E3%83%88%E3%83%AA%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%81%A7%E3%81%99%E3%80%82)
[^7]: [Whisper](https://github.com/openai/whisper)