---
title: "Metaの新しいAI諮問委員会が物議を醸す：男女間・人種間格差とその影響"
categories:
  - テクノロジー
tags:
  - 人工知能
  - ダイバーシティ
---
Metaが新たに設立したAI諮問委員会の全メンバーが白人男性で構成されていることが議論を呼んでいます。

## 新しいAI諮問委員会の発表
Metaは先週水曜日、新しいAI諮問委員会を発表しました。この委員会の全メンバーが白人男性で構成されている点が注目されています。多様性の欠如に抗議する声は長らく存在しており、特にAI分野においては多様な視点が必要とされています。現在の状況では、AI開発において女性や有色人種が依然として疎外されていると指摘されています。MetaはAI諮問委員会についてのコメントを控えています。

## 諮問委員会の役割とその構成
この諮問委員会は、Metaの取締役会や監査委員会とは異なり、技術革新や成長戦略に対する洞察と提言を行うために設立されました。しかし、この委員会には倫理学者（ethicist）や学術的背景を持つ研究者がおらず、すべてビジネスパーソンと起業家で構成されています[^1][^2]。これはAIの複雑さとリスクを考慮すると重大な欠陥です。

## AI技術とその影響
AI技術は多くの分野で急速に進化していますが、その影響は特に脆弱なコミュニティに対して深刻です。AI Now InstituteのSarah Myers West氏によれば、AIの開発過程や運用について批判的に検討し、公共の利益が守られるようにすることが重要です[^3]。現状、AI技術のエラーは均等に分布しておらず、差別的な影響を強化する可能性が高いです。

例えば、2019年にSensity AIが発見したように、オンラインで公開されているAI生成コンテンツ（AI-generated content）の96%が非合意の性的な動画でした[^4]。有名例では、今年1月、テイラー・スウィフトのポルノグラフィックなディープフェイク（deepfake）動画がX（旧Twitter）で広まりました[^5]。非有名人の場合、このような被害から保護される手立てはほとんどないという現実があります。

## 女性とAIのダークサイド
女性は特にAI技術の悪影響を受けやすい傾向があります。ディープフェイク技術の普及により、多くの女性がオンライン上での非合意的なポルノグラフィーの対象とされています。例えば、Perky AIと呼ばれるアプリは、写真から服を取り除く機能を提供していました。このアプリの広告には、16歳時のジェナ・オルテガの画像が使用されていました[^6]。このような広告がMetaの監視をすり抜けることがある点も問題視されています。

## 人工知能と差別
AI技術は既存の社会構造と同様に、多くの偏見（bias）を内包しています。例えば、顔認識（facial recognition）技術が黒人を犯罪容疑者として誤認識する頻度は、白人よりも高いことが示されています[^7]。また、音声アシスタントが多様なアクセントを理解するのに苦労することもあります。アルゴリズムが差別的なデータに基づいてトレーニングされると、その偏見がそのまま機械学習の結果に反映されます[^8]。

## 今後の課題と展望
AI技術の進展には多様な意見と視点が必要とされます。これまで除外されてきた女性や有色人種の声を取り入れることが不可欠です。技術が全ての人に対して公平であるためには、研究から社会的な理解までを網羅する複雑な層が必要です。Metaの現在のAI諮問委員会ではこの課題に対処できるとは考えにくいですが、新しいスタートアップや取り組みがこのギャップを埋める可能性があります。

## まとめ
Metaの新しいAI諮問委員会の構成は、多くの議論を引き起こしています。技術の多様性と公平性を確保するためには、さらなる努力と変革が求められます。多様な視点を取り入れることで、持続可能で包摂的な技術の未来が築けるでしょう。

## 参考URL
[^1]:[ethicist](https://www.ei-navi.jp/dictionary/content/ethicist/#:~:text=%E5%80%AB%E7%90%86%E5%AD%A6%E3%82%92%E5%B0%82%E6%94%BB%E3%81%99%E3%82%8B%E5%93%B2%E5%AD%A6%E8%80%85%E3%80%82,)
[^2]:[algorithm](https://ejje.weblio.jp/content/algorithm)
[^3]:[generative AI](https://www.nri.com/jp/knowledge/glossary/lst/sa/generative_ai)
[^4]:[AI-generated content](https://ai-accord.com/?p=46#:~:text=%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E7%94%9F%E6%88%90%EF%BC%9A-,AIGC%EF%BC%88AI%20Generated%20Content%EF%BC%89%E3%81%A8%E3%81%AF%EF%BC%9F,%E3%82%92%E7%94%9F%E6%88%90%E3%81%99%E3%82%8B%E3%81%93%E3%81%A8%E3%81%A7%E3%81%99%E3%80%82)
[^5]:[deepfake](https://aismiley.co.jp/ai_news/deepfake/)
[^6]:[intersectionality](https://www.hurights.or.jp/archives/newsletter/section4/2018/01/intersectionality.html#:~:text=%E3%81%93%E3%81%AEintersectionality%EF%BC%88%E4%BA%A4%E5%B7%AE%E6%80%A7%EF%BC%89%E3%81%A8,%E3%81%A6%E3%81%84%E3%82%8B%E7%8A%B6%E6%B3%81%E3%82%92%E3%81%95%E3%81%99%E3%80%82)
[^7]:[facial recognition](https://www.ei-navi.jp/dictionary/content/facial%2Brecognition/#:~:text=of%20known%20faces.-,%E7%94%9F%E4%BD%93%E8%AA%8D%E8%A8%BC%E3%81%A7%E3%80%81%E4%BA%BA%E3%81%AE%E9%A1%94%E3%82%92%E8%AA%AD%E3%81%BF%E5%8F%96%E3%81%A3%E3%81%A6%E6%97%A2%E7%9F%A5,%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%81%A8%E7%85%A7%E5%90%88%E3%81%99%E3%82%8B%E3%80%82)
[^8]:[bias](https://ejje.weblio.jp/content/bias)
