---
title: "元OpenAIスタッフ、安全性と透明性を求める声を上げる：生成AIの未来を守るために"
categories:
  - テクノロジー
tags:
  - AI
  - 安全性
  - 透明性
---
TechCrunchの初のAIニュースレターへようこそ。このニュースレターでは、毎週注目のAIモデルや重要なニュースを一挙にお届けします。

## 元OpenAIスタッフ、安全性と透明性を訴える

今週のAIニュースで取り上げるのは、OpenAIに関連する問題です。元OpenAI社員のグループが、組織内の安全対策に重大な欠陥があると主張し、New York Timesの記者Kevin Rooseに対して発言しました。彼らは、AIシステムが潜在的に危険な状態にならないようにするための対策が不十分であるとし、オープンな批判を支持する文化を求めています。

グループは火曜日に公開書簡を発表し、OpenAIを含む主要なAI企業に対して透明性を高め、内部告発者[^1]を保護する措置を求めました。「政府による効果的な監督がない限り、現役および元社員は、これらの企業を公衆に対して責任を持つべき人々の一部である」と手紙に記されています。

現状、OpenAIの安全委員会にCEOのサム・アルトマンを始め、すべてのメンバーが社内の人間で構成されているため、変革は期待しにくい[^2]。例えばアルトマンは、一度はOpenAIの制限的な発言禁止条項[^3]に関する知識を否定していましたが、その設立書類にはアルトマン自身の署名がありました。

## AI関連の最新ニュース

### ChatGPTプラットフォームの障害
OpenAIのAI搭載チャットプラットフォーム、ChatGPTが他社のAIサービスとともに今朝一斉にダウンし、その原因は不明状態です。

### OpenAIとヘリオン・エナジーの提携
Wall Street Journalによると、OpenAIはヘリオン・エナジーと電力供給契約を交渉中です。アルトマンは375億ドルの出資を行い、同社の取締役会に名前を連ねていますが、交渉には関与していないとのことです。

### データライセンシングの課題
TechCrunchは、高価なデータライセンシング契約がAI研究を小規模組織や学術機関にとって持続不可能にするリスクについて分析しています[^4]。

### AIによる憎悪音楽生成の問題
悪意あるユーザーがAIを用いた音楽生成ツールを悪用し、差別的な楽曲を生成・公開する事例が増えています。

## 研究論文の紹介

2023年に発表されたOpenAIの研究論文「Let's Verify Step by Step」において、GPT-4が数学問題を解く精度を向上させるために「プロセススーパービジョン」[^5]という新たなアプローチを使用しています。この手法は、各ステップごとに正確性を評価する報酬モデル[^6]を用いていますが、一般的な領域にどこまで適用できるかは不明です。

## モデルの紹介

天気予報の分野では、Microsoftが新たに開発した「Aurora」モデル[^7]が注目されています。このモデルは、数百万時間にわたる気象シミュレーションデータを元に学習しており、従来の数値予測システム[^8]を大幅に上回る精度を誇ります。

## まとめ

AIの安全性と透明性は、今後も大きな議論を呼びそうです。元OpenAIスタッフの声は業界にどれだけの影響を与えるのか、注視していきたいと思います。

## 参考URL

[^1]: [Whistleblower](https://eow.alc.co.jp/search?q=whistleblower)
[^2]: [Transparency](https://ejje.weblio.jp/content/transparency)
[^3]: [Nondisparagement Clause](https://www.law.cornell.edu/wex/nondisparagement_clause)
[^4]: [Data Licensing](https://legal.thomsonreuters.com/en/insights/articles/data-licensing-taking-into-account-data-ownership)
[^5]: [Process Supervision](https://openai.com/index/improving-mathematical-reasoning-with-process-supervision/)
[^6]: [Reward Model](https://qiita.com/omiita/items/c355bc4c26eca2817324)
[^7]: [Probabilistic Model](https://ejje.weblio.jp/content/probabilistic+model)
[^8]: [Numerical Prediction](https://www.dbs.ifi.lmu.de/Lehre/KDD/SS16/skript/7_Numerical_Prediction.pdf)
[^9]: [Universal Basic Income](https://www.nomuraholdings.com/jp/csr/sustainable/finance/research/rs202012_12.html#:~:text=%E3%81%AE%E5%8F%AF%E8%83%BD%E6%80%A7-,%E6%96%B0%E5%9E%8B%E3%82%B3%E3%83%AD%E3%83%8A%E7%A6%BD%E3%81%A7%E6%8F%BA%E3%82%89%E3%81%90%E6%89%80%E5%BE%97%E4%BF%9D%E9%9A%9C%E3%81%A8,%E3%83%99%E3%83%BC%E3%82%B7%E3%83%83%E3%82%AF%E3%82%A4%E3%83%B3%E3%82%AB%E3%83%A0%E3%81%AE%E5%8F%AF%E8%83%BD%E6%80%A7&text=UBI%E3%81%A8%E3%81%AF%E3%80%81%E5%85%A8%E3%81%A6%E3%81%AE,%E6%94%AF%E7%B5%A6%E3%81%8C%E5%8F%AF%E8%83%BD%E3%81%A7%E3%81%82%E3%82%8B%E3%80%82)
[^10]: [Safety Commission](https://eow.alc.co.jp/search?q=safety+commission)
