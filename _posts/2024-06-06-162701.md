---
title: "GoogleのソフトウェアエンジニアリングにおけるAIの進展と今後の展望"
categories:
  - テクノロジー
tags:
  - 生成AI
  - ソフトウェア開発
---
Googleでは、ソフトウェアエンジニアリングにおいてAIがどのように進化してきたか、今後の展望について解説します。

## はじめに
2019年、ソフトウェアエンジニアは機械学習[^1]の進展を認知しつつも、自分たちの業務にどのように役立つかは想像していませんでした。しかし、2024年には、多くのエンジニアがAIのコード生成補助による恩恵を享受しています。Google内部のツールや市販されている製品を利用し、ML（機械学習）ベースのオートコンプリート[^2]を活用する場面も増えています。本記事では、Googleの内部ソフトウェア開発ツールにおける最新のAI機能改善を紹介し、今後5年間での変化とその展望について論じます。

## 課題とアプローチ
AI技術の進展は目まぐるしく、どのアイデアを優先して探求すべきかの決定は困難です。我々は以下の3つのガイドラインを基に、アイデアの製品化に取り組んでいます:

1. 技術的な実現可能性と影響力の優先順位付け
2. UX[^3]（ユーザーエクスペリエンス）とモデル品質[^4]の向上
3. 効果の測定と評価

このアプローチに基づき、製品開発のサイクルを進めています。

## LLMを利用したソフトウェア開発
Transformerアーキテクチャ[^5]の普及に伴い、大規模言語モデル（LLMs）[^6]をソフトウェア開発に応用し始めました。特に注目すべきは、LLMベースのコード補完です。この技術は自然言語処理を利用してコードの補完を行うため、エンジニアにとって自然な操作感があります。また、効果測定も比較的容易です。

### 実績と応用
過去のブログで紹介した通り、コード補完のユーザー体験とその効果測定に多大な成果が見られています。例えば、エンジニアの37%がAI補助の提案を採用し、コードの50%がAIによって補完されています[^7]。高精度なデータを活用し、モデルの精度とUXを継続的に向上させることで、さらに多くの改善が見込まれます。

### 他の応用例
コードレビューのコメントの解決においても、AIが大きな役割を果たしています。この他、自然言語入力によるコード編集の指示や、ビルド失敗の修正予測[^8]などの新しい応用が進んでいます。

## 学びと改善のポイント
これまでの作業から学んだ主なポイントは次の通りです:

- UXとワークフローの自然な融合が高い効果をもたらす
- AIによる提案のレビューは重要であり、バランスが求められる
- オンラインA/Bテスト[^9]による迅速な試行錯誤が鍵
- Googleエンジニアのデータに基づく高品質なモデル設計

## 今後の展望
今後は、GoogleのDIDACTプロジェクトと協力し、最新の基盤モデル（Geminiシリーズ）を活用して更なるソフトウェア開発支援を実現します。業界全体でも、MLベースのコード補完がエンジニアに大きな効果を与えています。特に、テスト、コード理解、コードメンテナンスなど、幅広いソフトウェアエンジニアリング活動へのML支援が期待されています。

これにより、共通のベンチマーク[^10]を確立し、業界全体の進歩を促進することが重要です。特に、バグ解決やプロダクションデバッグなど、企業環境に特化したベンチマークが求められています。

## まとめ
Googleでは、AI技術を活用したソフトウェア開発ツールの進化が進んでいます。これからもAI技術の発展と共に、より高い生産性とユーザー体験の向上を目指していきます。

## 参考URL
[^1]:[Machine Learning](https://www.nttdata-gsl.co.jp/related/column/what-is-machine-learning.html#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%EF%BC%88Machine%20Learning%EF%BC%89%E3%81%A8,%E3%81%99%E3%82%8B%E3%83%87%E3%83%BC%E3%82%BF%E8%A7%A3%E6%9E%90%E6%8A%80%E8%A1%93%E3%81%A7%E3%81%99%E3%80%82)
[^2]:[Code Completion](https://en.wikipedia.org/wiki/Code_completion)
[^3]:[User Experience (UX)](https://www.brainpad.co.jp/rtoaster/blog/about_ux/)
[^4]:[Model Quality](https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/model-monitor-model-quality.html)
[^5]:[Transformer Architectures](https://ja.wikipedia.org/wiki/Transformer_(%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB))
[^6]:[Large Language Models (LLMs)](https://en.wikipedia.org/wiki/Large_language_model)
[^7]: Googleの機密データ
[^8]: Googleの機密データ
[^9]:[A/B Testing](https://www.innovation.co.jp/urumo/split_testing/#:~:text=A%2FB%E3%83%86%E3%82%B9%E3%83%88%E3%81%A8%E3%81%AF%E3%80%81%E3%83%90%E3%83%8A%E3%83%BC%E3%82%84%E5%BA%83%E5%91%8A%E6%96%87%E3%80%81,%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82)
[^10]:[Benchmarking](https://ejje.weblio.jp/content/benchmarking)
