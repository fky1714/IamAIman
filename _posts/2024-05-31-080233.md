---
title: "政治家の声クローンは依然として簡単に作成可能"
categories:
  - テクノロジー
tags:
  - 生成AI
  - ディープフェイク
---
2024年の選挙では、候補者の偽造音声やビデオが大きな要因となりうると予想されています。

## 政治家の声クローンの現状

選挙活動が本格化する中、有権者は注意が必要です。新しい研究が示すように、大統領から一般的な政治家までの大物政治家の声のクローンを生成するサービスが非常に少ない抵抗に遭っています。この研究は、デジタルヘイト対策センターが行ったもので、6つのAI搭載の声クローンサービスに注目しました[^1]。サービスは、Invideo AI、Veed、ElevenLabs、Speechify、Descript、及びPlayHTです。

## 研究結果

各サービスで、8人の主要な政治家の声をクローンし、それぞれに5つの偽の発言を生成させると、全240回の要求のうち193回が成功し、偽の政治家の音声を生成しました。一部のサービスは、偽情報のスクリプトの生成まで支援しました[^2]。例えば、偽のイギリス首相リシ・スナックの音声が「個人的な費用を支払うために選挙資金を使ってしまったことは誤りであり、本当に申し訳なく思う」と謝罪するものでした。

## サービスの反応

調査において、SpeechifyとPlayHTは40回の要求に対してすべての声と偽の発言をブロックしませんでした。Descript、Invideo AI、およびVeedは、発言の音声をアップロードする必要がある安全策を講じていましたが、他のサービスで生成された音声を「本物」として使用することでこれを容易に回避できました。唯一、ElevenLabsだけが公共の人物の声のクローンを作成することをポリシーに反しているとし、40回中25回でブロックしましたが、残りの15回はEUの政治家のものだったため許可された可能性があります[^3]。

## Invideo AIの問題点

特に悪名高いのはInvideo AIで、制限を回避した場合、偽の大統領バイデンが投票所での爆弾予告について警告するスクリプトを生成しました[^4]。短いプロンプトに基づいて、自動的に偽情報のスクリプトを即興で作成し、1分間のビデオを生成しました。このビデオでは、バイデンの声が投票を避けるよう国民に説得し、爆弾の脅威の深刻さを説明しました。

## ディープフェイクとその法的問題

既に、偽のバイデンの声が違法なロボコール[^5]と組み合わされ、特定の地域に偽の公共サービス発表を流布する手段として使用されています。FCCはこれを違法としましたが、主に既存のロボコール規制に基づくもので、偽装やディープフェイク[^6]に関するものではありません。

## まとめ

これらのプラットフォームが政策を強制できなければ、この選挙シーズンにはクローン流行が起こる可能性があります。選挙におけるディープフェイクの影響についての警戒が必要です。

## 参考URL
[^1]:[Voice cloning](https://elevenlabs.io/voice-cloning)
[^2]:[Deepfake](https://aismiley.co.jp/ai_news/deepfake/)
[^3]:[Disinformation](https://eow.alc.co.jp/search?q=disinformation)
[^4]:[Audio prompt](https://ejje.weblio.jp/content/audio+prompt)
[^5]:[Script generation](https://www.synthesia.io/features/ai-script-generator)
[^6]:[Robocalling](https://ejje.weblio.jp/content/robocall)
[^7]:[Impersonation](https://eow.alc.co.jp/search?q=impersonation)
