---
title: "ChatDirector: 新たなビデオ会議体験を創出する空間認識と音声駆動レイアウト"
categories:
  - テクノロジー
tags:
  - 生成AI
  - ビデオ会議
---
Googleの最新プロトタイプ「ChatDirector」が、空間認識シーンレンダリングと音声駆動レイアウトの技術を駆使して、ビデオ会議をよりリアルに、より効果的に変革します。

## ChatDirectorの概要

ビデオ会議システムは、個人やプロフェッショナルの設定で一般的に使用されています。しかし、従来の2Dスクリーンのグリッドレイアウトは対面のコミュニケーションに比べて流動性やニュアンスに乏しいことが多いです。そこでGoogleの新しいプロトタイプ「ChatDirector」は、空間認識ビデオアバター、共有3Dシーン、自動レイアウトトランジションを導入することで、この問題を解決します[^1][^2]。

## 設計の考慮点

ChatDirectorの設計において、以下の重要なポイントが考慮されています：
1. **空間認識の可視化**〔DC1〕[^3]：
   参加者をテーブルの周りに配置し、共感覚を持たせることが重要です。
2. **音声駆動の支援**〔DC2〕：
   参加者が会話の流れを維持しやすくするために、デジタル機能を提供します。
3. **視覚的合図の再現**〔DC3〕：
   頭の動きや視線の方向など、動的な物理的動作を視覚化します。
4. **認知負荷の最小化**〔DC4〕：
   同時に表示される情報を最小限に抑え、注意の分散を防ぎます。
5. **互換性と拡張性**〔DC5〕[^4]：
   標準ビデオ会議機器と互換性を持たせ、広く普及させることが重要です。

## 空間認識シーンレンダリングパイプライン

ChatDirectorは、参加者の視覚的存在を3Dポートレートアバターとして再構築するために、U-Netを基本とした深度推定ニューラルネットワークを使用しています[^5][^6][^7]。このパイプラインは、RGBと深度画像を入力として3Dポートレートアバターメッシュを生成します。

### システムアーキテクチャ

システムアーキテクチャは、次のように機能します：
1. ローカルユーザーのデバイス上で、音声入力とWeb Speech APIを使用して認識された音声テキスト、RGB画像、深度画像をストリーミングします[^8]。
2. 各リモートユーザーのデータを受信し、3Dポートレートアバターを再構築して表示します。

## 音声駆動レイアウトトランジションアルゴリズム

本アルゴリズムは、進行中の会話に基づいてレイアウトやアバターの動作を調整し、参加者が自然に会話の流れを追うことができるようにしています[^9]。入力として、各参加者の発言状態 (Quiet, Talk-To, Announce) をモデル化し、Web Speech APIを使って検出します[^10]。

出力として、レイアウト状態とアバター状態が生成されます：
- **レイアウト状態**：会議シーンの全体的な可視化を決定します。例えば、'One-on-One'、'Pairwise'、'Full-view' などのモードがあります。
- **アバター状態**：各アバターの向きを制御します。例えば、ローカルユーザーや他のリモート参加者に向かって回転します。

## 定性的パフォーマンス評価

ChatDirectorの効果を評価するために、16名の参加者を対象としたラボスタディを実施しました。その結果、標準のビデオ会議システムに比べて、スピーチハンドリングの課題が大幅に改善されたことが明らかになりました[^11]。また、共同存在感やエンゲージメントが向上することが示されました[^12]。

## まとめ

ChatDirectorは、音声駆動の視覚的キューを使用した空間認識シーンを活用して、ビデオ会議をより没入感のあるものにする新しいプロトタイプです。将来的には、デジタル肖像に関する制御問題を含め、責任あるAIの考慮が必要です。本ツールが展開される際には、ユーザーの同意に基づいて動作し、倫理的ガイドラインを順守することが欠かせません。

## 参考URL
[^1]:[Paper](https://research.google/pubs/chatdirector-enhancing-video-conferencing-with-space-aware-scene-rendering-and-speech-driven-layout-transition/)
[^2]:[Space-aware scene rendering](https://research.google/pubs/chatdirector-enhancing-video-conferencing-with-space-aware-scene-rendering-and-speech-driven-layout-transition/)
[^3]:[3D video avatars](https://note.com/taziku/n/nf237bf6f7d5b)
[^4]:[WebRTC](https://imageflux.sakura.ad.jp/column/webrtc/#:~:text=WebRTC%EF%BC%88Web%20Real%2DTime%20Communication,%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%85%B1%E6%9C%89%E3%81%8C%E3%81%8A%E3%81%93%E3%81%AA%E3%81%88%E3%81%BE%E3%81%99%E3%80%82)
[^5]:[U-Net](https://www.acceluniverse.com/blog/developers/2019/11/u-net.html#:~:text=U%2Dnet%E3%81%A8%E3%81%AF,%E3%81%AB%E7%99%BA%E8%A1%A8%E3%81%95%E3%82%8C%E3%81%BE%E3%81%97%E3%81%9F%E3%80%82)
[^6]:[MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/guide)
[^7]:[Depth inference neural network](http://ieeexplore.ieee.org/abstract/document/7051531/)
[^8]:[Web Speech API](https://developer.mozilla.org/ja/docs/Web/API/Web_Speech_API)
[^9]:[Decision-tree algorithm](https://scikit-learn.org/stable/modules/tree.html)
[^10]:[Speech States](https://learn.microsoft.com/ja-jp/dotnet/api/system.speech.synthesis.speechsynthesizer.state?view=dotnet-plat-ext-8.0)
[^11]:[Temple Presence Inventory (TPI)](http://matthewlombard.com/research/p2_ab.html)
[^12]:[Space-aware scene rendering](https://research.google/pubs/chatdirector-enhancing-video-conferencing-with-space-aware-scene-rendering-and-speech-driven-layout-transition/)
