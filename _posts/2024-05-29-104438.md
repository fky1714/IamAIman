---
title: "生成AIの信頼性向上：新たな枠組みAGREEの紹介"
categories:
  - 技術
tags:
  - 生成AI
  - 自然言語処理
---
大規模言語モデル(LLM)の適応による信頼性向上についての記事です。Googleが開発した新しいフレームワークAGREEを紹介します。

## はじめに
近年、大規模言語モデル（LLM）は、複数の能力において驚異的な進歩を遂げてきました。特に、多段階の推論、計画の生成、ツールやAPIの使用といった分野での成果が目立っています。しかし、現実世界での展開において、これらのモデルの信頼性は「幻覚」と呼ばれる問題によってしばしば低下しています。幻覚とは、実際には存在しない情報を生成する現象を指します[^1]。この問題は、幅広い知識を必要とするオープンエンドのクエリに対して特に発生しやすく、ニュース報道や教育コンテンツなど、高い事実精度が求められる分野においてリスクを伴います。

## 幻覚問題を解決するためのグラウンディング
グラウンディングとは、LLMが提供する情報を信頼できるソースに結び付ける手法です。このシステムは、一貫性と有用な応答を提供するだけでなく、外部知識への関連する引用をサポートすることで、その主張を裏付けます[^2]。これを念頭に置き、私たちの論文「Effective large language model adaptation for improved grounding」において、新たなグラウンディングフレームワーク「AGREE」（Adaptation for GRounding EnhancEment）を紹介します。AGREEは、LLMが応答内の主張を自己グラウンディングし、正確な引用を提供する能力を備え、ユーザーの信頼を高めることができます。

## AGREEの概要
AGREEは、学習ベースの適応とテスト時適応（TTA）を組み合わせることで、LLMのグラウンディングと引用生成を改善します。これにより、前のプロンプトベースのアプローチとは異なり、LLMが応答内の主張を自己グラウンディングし、正確な引用を提供する能力を持つように調整されます。

### 学習時の適応
AGREEは、ラベルのないクエリから合成データを収集し、基礎LLMを適応させます。この過程で、リトリーバーモデルを使用して信頼性のあるソース（例：Wikipedia）から関連するパッセージを取得し、それを基礎LLMに提示します[^3][^4]。次に、自然言語推論（NLI）モデルを使用して初期応答に引用を追加します[^5]。このようにして作成されたデータを使用して、基礎LLMをチューニングし、引用を含む応答を生成する能力を向上させます。

### テスト時の適応
テスト時には、AGREEは逐次的推論戦略を導入し、LLMが自己生成した引用に基づいて追加情報を積極的に検索する能力を持ちます。具体的には、まずリトリーバーモデルを使用して初期パッセージを取得し、その後、引用情報に基づいて追加情報を提供することで逐次的に精緻化します[^6]。

## 実験と結果
我々は、5つのデータセットを使用してAGREEの効果を実証しました。これには、ベースLLMの適応に使用された2つのインドメイン・データセット（NQおよびStrategyQA）と、外部ドメイン・データセット（ASQA、QAMPARI、および内部QAデータセット「Enterprise」）が含まれます[^7][^8][^9]。AGREEを2つのLLMに適用し、競争力のあるプロンプトベースのベースライン（ICLCite）およびポストホック・サイティング・ベースライン（PostCite）と比較しました。結果、AGREEが各ベースラインを大幅に上回る性能を示しました[^10]。

## まとめ
AGREEは、LLMで生成されたコンテンツの事実性と検証性を向上させるための効果的な学習ベースのアプローチです。我々の評価は、プロンプトやLLMのパラメトリックな知識に依存するアプローチに比べて、包括的適応アプローチの利点を示しています。AGREEは、信頼性の高い言語モデルの構築に向けた一歩を示しており、さらなる研究と発展が期待されます。

## 参考URL
[^1]: [Hallucination](https://eow.alc.co.jp/search?q=hallucination)
[^2]: [Grounding](https://eow.alc.co.jp/search?q=grounding)
[^3]: [Retriever Model](https://tech.acesinc.co.jp/entry/2023/03/31/121001)
[^4]: [Prompting](https://eow.alc.co.jp/search?q=prompting)
[^5]: [Natural Language Inference (NLI)](https://shunk031.github.io/paper-survey/summary/nlp/Character-level-Intra-Attention-Network-for-Natural-Language-Inference)
[^6]: [Test-Time Adaptation (TTA)](https://arxiv.org/abs/2303.15361)
[^7]: [Pre-Trained LLM](https://huggingface.co/transformers/v4.4.2/pretrained_models.html)
[^8]: [In-Domain Dataset](https://www.anlp.jp/proceedings/annual_meeting/2016/pdf_dir/A4-3.pdf)
[^9]: [Out-of-Domain Dataset](https://www.quora.com/What-is-in-domain-out-domain-and-open-domain-data)
[^10]: [Zero-Shot Setting](https://en.wikipedia.org/wiki/Zero-shot_learning)